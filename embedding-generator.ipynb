{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = 'documents/'\n",
    "contents = {}  # Dictionary to store file contents\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    # Check if it's a file and not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            contents[filename] = file.read()  # Read and store file content\n",
    "            \n",
    "texts = list(contents.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings: tensor([[ 0.0167,  0.0076,  0.0121,  ...,  0.0299, -0.0065, -0.0162],\n",
      "        [-0.0075, -0.0031, -0.0314,  ..., -0.0181, -0.0515, -0.0038],\n",
      "        [ 0.0047, -0.0240, -0.0088,  ..., -0.0313, -0.0133, -0.0198],\n",
      "        ...,\n",
      "        [-0.0170, -0.0106, -0.0202,  ...,  0.0073,  0.0111, -0.0304],\n",
      "        [ 0.0060,  0.0052,  0.0010,  ..., -0.0232, -0.0033,  0.0208],\n",
      "        [ 0.0230,  0.0092, -0.0152,  ...,  0.0374, -0.0125, -0.0185]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-large-en-v1.5')\n",
    "model = AutoModel.from_pretrained('BAAI/bge-large-en-v1.5')\n",
    "model.eval()\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "    # Perform pooling. In this case, cls pooling.\n",
    "    sentence_embeddings = model_output[0][:, 0]\n",
    "# normalize embeddings\n",
    "sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "print(\"Sentence embeddings:\", sentence_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sentence_embeddings, \"embeddings/document_embeddings.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
